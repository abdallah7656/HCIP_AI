{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **download data**"
      ],
      "metadata": {
        "id": "LpyERLqIqKNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Naive Bayesian text classification](https://)\n",
        " "
      ],
      "metadata": {
        "id": "G-H21odj85Lp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importing Related Library**"
      ],
      "metadata": {
        "id": "hLhpu6B06Wdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "Cui1k70o6VsY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J1o835Qt6Vub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "R64__XRV9MNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_str(string):\n",
        " \"\"\"\n",
        " Tokenization/string cleaning for all datasets except for SST.\n",
        " Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
        " \"\"\"\n",
        " string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        " string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        " string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        " string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        " string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        " string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        " string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        " string = re.sub(r\",\", \" , \", string)\n",
        " string = re.sub(r\"!\", \" ! \", string)\n",
        " string = re.sub(r\"\\(\", \" \\( \", string)\n",
        " string = re.sub(r\"\\)\", \" \\) \", string)\n",
        " string = re.sub(r\"\\?\", \" \\? \", string)\n",
        " string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        " return string.strip().lower()\n",
        " \n"
      ],
      "metadata": {
        "id": "u_kCVwZ16VxG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_data_and_labels(positive_data_file, negative_data_file):\n",
        " \"\"\"\n",
        " Loads MR polarity data from files, splits the data into words and generates labels.\n",
        " Returns split sentences and labels.\n",
        " \"\"\"\n",
        " # Load data from files\n",
        " positive_examples = list(open(positive_data_file, \"r\", encoding='iso-8859-1').readlines()) \n",
        " positive_examples = [s.strip() for s in positive_examples]\n",
        " negative_examples = list(open(negative_data_file, \"r\", encoding='iso-8859-1').readlines()) \n",
        " negative_examples = [s.strip() for s in negative_examples]\n",
        " # Split by words\n",
        " x = positive_examples + negative_examples\n",
        " x = [clean_str(sent) for sent in x]\n",
        " x = np.array(x)\n",
        " # Generate labels\n",
        " positive_labels = [1] * len(positive_examples)\n",
        " negative_labels = [0] * len(negative_examples)\n",
        " y = np.concatenate([positive_labels, negative_labels], 0)\n",
        " \n",
        " \n",
        " shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
        " shuffled_x = x[shuffle_indices]\n",
        " shuffled_y = y[shuffle_indices]\n",
        " return shuffled_x, shuffled_y\n"
      ],
      "metadata": {
        "id": "Y9UZhrUn66KK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data:"
      ],
      "metadata": {
        "id": "PrDIsBY29gGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "positive_data_file = 'data/rt-polarity.pos'\n",
        "negative_data_file = 'data/rt-polarity.neg'\n",
        "x, y = load_data_and_labels(positive_data_file, negative_data_file)"
      ],
      "metadata": {
        "id": "TuBb6zDO6V09"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "show data"
      ],
      "metadata": {
        "id": "AW6mJlcdBIBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x[:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pwg_X34BG0T",
        "outputId": "41b1d838-e46a-4523-80e1-254253f565fd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['flounders due to the general sense that no two people working on the production had exactly the same thing in mind',\n",
              "       \"cusack 's just brilliant in this\",\n",
              "       'there are a couple of things that elevate glory above most of its ilk , most notably the mere presence of duvall',\n",
              "       'too silly to take seriously',\n",
              "       'the only way to tolerate this insipid , brutally clueless film might be with a large dose of painkillers'],\n",
              "      dtype='<U266')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show data labels: \n"
      ],
      "metadata": {
        "id": "IzblgJCCBVwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y[:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV8bgxNeBG2Y",
        "outputId": "508a56b7-afba-457d-fdc2-aad354beaf0e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "split and map"
      ],
      "metadata": {
        "id": "BO25vvBOBiYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 2000\n",
        "x_train, y_train = x[:-2000], y[:-2000]\n",
        "x_test, y_test = x[-2000:], y[-2000:]\n",
        "label_map = {0: 'negative', 1: 'positive'}\n"
      ],
      "metadata": {
        "id": "pQ2iV1g6BG6S"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the main class of the classifier and define the training and test functions."
      ],
      "metadata": {
        "id": "RoD0AUXmDONI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NB_Classifier(object):\n",
        " \n",
        " def __init__(self):\n",
        "   # naive bayes\n",
        "   self.model = MultinomialNB( alpha=1) #Laplace smooth：1 \n",
        "   # use tf-idf extract features\n",
        "   self.feature_processor = TfidfVectorizer()\n",
        " \n",
        " def fit(self, x_train, y_train, x_test, y_test):\n",
        "   # tf-idf extract features\n",
        "   x_train_fea = self.feature_processor.fit_transform(x_train)\n",
        "   self.model.fit(x_train_fea, y_train)\n",
        " \n",
        "   train_accuracy = self.model.score(x_train_fea, y_train)\n",
        "   print(\"Training Accuracy：{}\".format(round(train_accuracy, 3)))\n",
        " \n",
        "   x_test_fea = self.feature_processor.transform(x_test)\n",
        "   y_predict = self.model.predict(x_test_fea)\n",
        "   test_accuracy = accuracy_score(y_test, y_predict)\n",
        "   print(\"Test Accuracy：{}\".format(round(test_accuracy, 3)))\n",
        " \n",
        "   y_predict = self.model.predict(x_test_fea)\n",
        "   print('Test set evaluate：')\n",
        "   print(classification_report(y_test, y_predict, target_names=['0', '1']))\n",
        " \n",
        " def single_predict(self, text):\n",
        "   text_fea = self.feature_processor.transform([text])\n",
        "   predict_idx = self.model.predict(text_fea)[0]\n",
        "   predict_label = label_map[predict_idx]\n",
        "   predict_prob = self.model.predict_proba(text_fea)[0][predict_idx]\n",
        " \n",
        "   return predict_label, predict_prob\n"
      ],
      "metadata": {
        "id": "f9JAsZ2vCFez"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize and train the classifier.\n",
        "\n"
      ],
      "metadata": {
        "id": "QbP8odFWFIOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_classifier = NB_Classifier()\n",
        "nb_classifier.fit(x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V85t-NclDzHS",
        "outputId": "dcdc6b38-eb5a-4511-f15b-813cb1546591"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy：0.928\n",
            "Test Accuracy：0.774\n",
            "Test set evaluate：\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.77      0.78      1016\n",
            "           1       0.77      0.78      0.77       984\n",
            "\n",
            "    accuracy                           0.77      2000\n",
            "   macro avg       0.77      0.77      0.77      2000\n",
            "weighted avg       0.77      0.77      0.77      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single sentence test"
      ],
      "metadata": {
        "id": "S5BQe5cIFVCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_classifier.single_predict(\"beautiful actors, great movie\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEClJH_HDzI_",
        "outputId": "5d2344b8-2fdd-4c6d-dbf1-16a94bbf7117"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('positive', 0.7148445135187691)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_classifier.single_predict(\"it's really boring\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb5PRZ6ODzMh",
        "outputId": "863da270-99ea-40fc-8f07-d763165fe2da"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('negative', 0.8787393394531633)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yRH9TTVICFnp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}